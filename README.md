# ğŸ™ï¸ Vietnamese Text-to-Speech System (TTS) ğŸ‡»ğŸ‡³ 

## ğŸŒŸ Introduction
This project develops a **Text-to-Speech (TTS) System** with advanced **voice cloning** capabilities tailored specifically for Vietnamese.  
It leverages state-of-the-art technologies such as **Deep Learning**, **Transformer**, **U-Net**, **Tacotron**, **FastSpeech**, **VITS**, and uses the **pretrained XTTS-v2** model.

---

## â–¶ï¸ Demo Video
ğŸ“º Watch the system demo [here](https://www.youtube.com/watch?v=LRkJD9daWrs)

---

## ğŸš€ Key Features
- ğŸ”Š **Vietnamese Text-to-Speech Conversion:** Generate natural, high-accuracy audio from text input.  
- ğŸ¤ **Voice Cloning:** Clone a voice from just a short sample recording.  
- ğŸšï¸ **Noise Reduction & Audio Enhancement:** Remove noise and unwanted sounds for clearer audio.  
- ğŸ” **Voice Similarity Analysis:** Compare and determine the similarity between different voices.

---

## ğŸ› ï¸ Technologies Used

### Frontend
- âš›ï¸ **React (with Vite):** Fast, efficient, and intuitive UI development.  
- ğŸ¨ **HTML/CSS/JavaScript:** Modern, user-friendly, and interactive interface design.  

### Backend
- ğŸ **Python 3.11:** Robust and scalable backend logic.  
- ğŸŒ **FastAPI:** High-performance, secure, and rapid API development framework.  
- ğŸ“š **TensorFlow, PyTorch:** Leading deep learning libraries for model training and deployment.  
- ğŸ§ **Librosa, Soundfile:** Advanced audio processing libraries for voice feature extraction and analysis.  

### Deep Learning Models
- ğŸ§  **Transformer** â€“ Efficient processing of natural language and audio.  
- ğŸ“¢ **Tacotron** â€“ Converts text into Mel Spectrograms.  
- ğŸš… **FastSpeech** â€“ Fast and stable speech synthesis without attention mechanisms.  
- ğŸ”Š **VITS** â€“ Combines VAE and GAN for highly natural speech.  
- ğŸŒ€ **U-Net** â€“ Noise reduction and audio enhancement.  
- ğŸ“Œ **XTTS-v2** â€“ Pretrained multilingual model optimized for Vietnamese.  

---

## ğŸ“‚ Project Structure

```
Voice_cloning_VN
â”‚
â”œâ”€â”€ fe        # Giao diá»‡n React
â”œâ”€â”€ be        # Backend FastAPI
â”œâ”€â”€ ai        # CÃ¡ch mÃ´ hÃ¬nh Deep Learning Ä‘Æ°á»£c huáº¥n luyá»‡n
â”œâ”€â”€ data      # Dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p, tiá»n xá»­ lÃ½ vÃ  sá»­ dá»¥ng

```
---

## ğŸ“‚ Dataset

The system was trained and evaluated on a variety of datasets:

- **[VLSP2020](https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/)** â€“ A Vietnamese speech dataset with over 100 hours of recorded audio, designed for speech processing research.

- **LibriSpeech** â€“ A large-scale, high-quality English speech dataset extracted from public audiobooks.

- **VoxCeleb** â€“ A diverse speech dataset collected from online videos of various celebrities.

- **AISHELL-3** â€“ A Mandarin Chinese speech dataset with multiple speakers, used for both TTS and ASR training.

- **VIVOS** â€“ A Vietnamese speech dataset consisting of short spoken sentences for speech recognition and synthesis.

- **[ESC-50](https://github.com/karolpiczak/ESC-50?tab=readme-ov-file)** â€“ A dataset of 2,000 labeled environmental audio recordings, each 5 seconds long, categorized into 50 semantic classes (40 samples per class).  
  The dataset is divided into 5 major categories:
  1. **Animal sounds** (e.g., chirping birds, barking dogs).
  2. **Natural soundscapes & water sounds** (e.g., rain, sea waves, wind).
  3. **Human non-speech sounds** (e.g., clapping, coughing, footsteps).
  4. **Indoor sounds** (e.g., keyboard typing, door opening, vacuum cleaner).
  5. **Urban noise/outdoor sounds** (e.g., traffic, sirens, trains).


---

## ğŸ“¸ Illustrations
### ğŸš§ Deep Learning Model Architecture
| | | | |
|---|---|---|---|
| ![](image/1.JPG) | ![](image/2.JPG) | ![](image/3.JPG) | ![](image/4.JPG) |

### ğŸ¨ System Design & Implementation
| | | | |
|---|---|---|---|
| ![](image/5.JPG) | ![](image/6.JPG) | ![](image/7.JPG) | ![](image/8.JPG) |

### ğŸ“Š Model Results
| | |
|---|---|
| ![](image/9.JPG) | ![](image/10.JPG) |

---

## ğŸš§ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t

### Clone Repository
```bash
git clone https://github.com/tttiuem2k3/Voice_cloning_VN.git
cd Voice_cloning_VN
```

### Backend
```bash
pip install -r requirements.txt
```

### Frontend
```bash
cd frontend
npm install
npm run dev
```

### Download Pretrained XTTS-v2 Model
```python
from huggingface_hub import snapshot_download
model_dir = r"./Model"
snapshot_download(repo_id="thinhlpg/viXTTS", repo_type="model", local_dir=model_dir)
```

---

## ğŸŒ± Contribution Guidelines
- â­ Star the repository
- ğŸ Report issues via [issues](https://github.com/tttiuem2k3/Voice_cloning_VN/issues)
- ğŸ“¥ Submit pull requests

---

## ğŸ“œ References

- [Tacotron](https://github.com/Rayhane-mamah/Tacotron-2)
- [FastSpeech](https://github.com/ming024/FastSpeech2)
- [XTTS-v2](https://huggingface.co/coqui/XTTS-v2)

---

##  ğŸ“ Contact
- ğŸ“§ Email: tttiuem2k3@gmail.com
- ğŸ‘¥ Linkedin: [Thá»‹nh Tráº§n](https://www.linkedin.com/in/thinh-tran-04122k3/)
- ğŸ’¬ Zalo - phone: +84 329966939 | +84 336639775

---
